{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"alexnet.ipynb","provenance":[],"authorship_tag":"ABX9TyPyAFTeGKfzw0f8gmwvCYnU"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"9CO-854nvEIl","executionInfo":{"status":"ok","timestamp":1602061328054,"user_tz":-330,"elapsed":1466,"user":{"displayName":"pytorch stuff","photoUrl":"","userId":"00602585404500228461"}},"outputId":"ba281170-679e-4dec-f830-bf22ab431ebd","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["\"\"\"\n","!pip install colabcode\n","from colabcode import ColabCode\n","\n","#ColabCode()\n","ColabCode(port=10000)\n","\"\"\""],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'\\n!pip install colabcode\\nfrom colabcode import ColabCode\\n\\n#ColabCode()\\nColabCode(port=10000)\\n'"]},"metadata":{"tags":[]},"execution_count":1}]},{"cell_type":"code","metadata":{"id":"QlynLa89S9JP","executionInfo":{"status":"ok","timestamp":1602089804334,"user_tz":-330,"elapsed":4236,"user":{"displayName":"pytorch stuff","photoUrl":"","userId":"00602585404500228461"}}},"source":["import torch\n","import torch.nn as nn\n","from torchvision import datasets, models\n","import numpy as np\n","import torch.nn.functional as F"],"execution_count":29,"outputs":[]},{"cell_type":"code","metadata":{"id":"C6_Ac_L7cGGL","executionInfo":{"status":"ok","timestamp":1602089804337,"user_tz":-330,"elapsed":4227,"user":{"displayName":"pytorch stuff","photoUrl":"","userId":"00602585404500228461"}},"outputId":"0b65f491-224a-41fb-e7f9-28e5245e0d3e","colab":{"base_uri":"https://localhost:8080/"}},"source":["help(nn.Conv2d)"],"execution_count":30,"outputs":[{"output_type":"stream","text":["Help on class Conv2d in module torch.nn.modules.conv:\n","\n","class Conv2d(_ConvNd)\n"," |  Applies a 2D convolution over an input signal composed of several input\n"," |  planes.\n"," |  \n"," |  In the simplest case, the output value of the layer with input size\n"," |  :math:`(N, C_{\\text{in}}, H, W)` and output :math:`(N, C_{\\text{out}}, H_{\\text{out}}, W_{\\text{out}})`\n"," |  can be precisely described as:\n"," |  \n"," |  .. math::\n"," |      \\text{out}(N_i, C_{\\text{out}_j}) = \\text{bias}(C_{\\text{out}_j}) +\n"," |      \\sum_{k = 0}^{C_{\\text{in}} - 1} \\text{weight}(C_{\\text{out}_j}, k) \\star \\text{input}(N_i, k)\n"," |  \n"," |  \n"," |  where :math:`\\star` is the valid 2D `cross-correlation`_ operator,\n"," |  :math:`N` is a batch size, :math:`C` denotes a number of channels,\n"," |  :math:`H` is a height of input planes in pixels, and :math:`W` is\n"," |  width in pixels.\n"," |  \n"," |  * :attr:`stride` controls the stride for the cross-correlation, a single\n"," |    number or a tuple.\n"," |  \n"," |  * :attr:`padding` controls the amount of implicit zero-paddings on both\n"," |    sides for :attr:`padding` number of points for each dimension.\n"," |  \n"," |  * :attr:`dilation` controls the spacing between the kernel points; also\n"," |    known as the Ã  trous algorithm. It is harder to describe, but this `link`_\n"," |    has a nice visualization of what :attr:`dilation` does.\n"," |  \n"," |  * :attr:`groups` controls the connections between inputs and outputs.\n"," |    :attr:`in_channels` and :attr:`out_channels` must both be divisible by\n"," |    :attr:`groups`. For example,\n"," |  \n"," |      * At groups=1, all inputs are convolved to all outputs.\n"," |      * At groups=2, the operation becomes equivalent to having two conv\n"," |        layers side by side, each seeing half the input channels,\n"," |        and producing half the output channels, and both subsequently\n"," |        concatenated.\n"," |      * At groups= :attr:`in_channels`, each input channel is convolved with\n"," |        its own set of filters, of size:\n"," |        :math:`\\left\\lfloor\\frac{out\\_channels}{in\\_channels}\\right\\rfloor`.\n"," |  \n"," |  The parameters :attr:`kernel_size`, :attr:`stride`, :attr:`padding`, :attr:`dilation` can either be:\n"," |  \n"," |      - a single ``int`` -- in which case the same value is used for the height and width dimension\n"," |      - a ``tuple`` of two ints -- in which case, the first `int` is used for the height dimension,\n"," |        and the second `int` for the width dimension\n"," |  \n"," |  Note:\n"," |  \n"," |       Depending of the size of your kernel, several (of the last)\n"," |       columns of the input might be lost, because it is a valid `cross-correlation`_,\n"," |       and not a full `cross-correlation`_.\n"," |       It is up to the user to add proper padding.\n"," |  \n"," |  Note:\n"," |  \n"," |      When `groups == in_channels` and `out_channels == K * in_channels`,\n"," |      where `K` is a positive integer, this operation is also termed in\n"," |      literature as depthwise convolution.\n"," |  \n"," |      In other words, for an input of size :math:`(N, C_{in}, H_{in}, W_{in})`,\n"," |      a depthwise convolution with a depthwise multiplier `K`, can be constructed by arguments\n"," |      :math:`(in\\_channels=C_{in}, out\\_channels=C_{in} \\times K, ..., groups=C_{in})`.\n"," |  \n"," |  Note:\n"," |      In some circumstances when using the CUDA backend with CuDNN, this operator\n"," |      may select a nondeterministic algorithm to increase performance. If this is\n"," |      undesirable, you can try to make the operation deterministic (potentially at\n"," |      a performance cost) by setting ``torch.backends.cudnn.deterministic =\n"," |      True``.\n"," |      Please see the notes on :doc:`/notes/randomness` for background.\n"," |  \n"," |  \n"," |  Args:\n"," |      in_channels (int): Number of channels in the input image\n"," |      out_channels (int): Number of channels produced by the convolution\n"," |      kernel_size (int or tuple): Size of the convolving kernel\n"," |      stride (int or tuple, optional): Stride of the convolution. Default: 1\n"," |      padding (int or tuple, optional): Zero-padding added to both sides of\n"," |          the input. Default: 0\n"," |      padding_mode (string, optional): ``'zeros'``, ``'reflect'``,\n"," |          ``'replicate'`` or ``'circular'``. Default: ``'zeros'``\n"," |      dilation (int or tuple, optional): Spacing between kernel elements. Default: 1\n"," |      groups (int, optional): Number of blocked connections from input\n"," |          channels to output channels. Default: 1\n"," |      bias (bool, optional): If ``True``, adds a learnable bias to the\n"," |          output. Default: ``True``\n"," |  \n"," |  Shape:\n"," |      - Input: :math:`(N, C_{in}, H_{in}, W_{in})`\n"," |      - Output: :math:`(N, C_{out}, H_{out}, W_{out})` where\n"," |  \n"," |        .. math::\n"," |            H_{out} = \\left\\lfloor\\frac{H_{in}  + 2 \\times \\text{padding}[0] - \\text{dilation}[0]\n"," |                      \\times (\\text{kernel\\_size}[0] - 1) - 1}{\\text{stride}[0]} + 1\\right\\rfloor\n"," |  \n"," |        .. math::\n"," |            W_{out} = \\left\\lfloor\\frac{W_{in}  + 2 \\times \\text{padding}[1] - \\text{dilation}[1]\n"," |                      \\times (\\text{kernel\\_size}[1] - 1) - 1}{\\text{stride}[1]} + 1\\right\\rfloor\n"," |  \n"," |  Attributes:\n"," |      weight (Tensor): the learnable weights of the module of shape\n"," |          :math:`(\\text{out\\_channels}, \\frac{\\text{in\\_channels}}{\\text{groups}},`\n"," |          :math:`\\text{kernel\\_size[0]}, \\text{kernel\\_size[1]})`.\n"," |          The values of these weights are sampled from\n"," |          :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})` where\n"," |          :math:`k = \\frac{groups}{C_\\text{in} * \\prod_{i=0}^{1}\\text{kernel\\_size}[i]}`\n"," |      bias (Tensor):   the learnable bias of the module of shape\n"," |          (out_channels). If :attr:`bias` is ``True``,\n"," |          then the values of these weights are\n"," |          sampled from :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})` where\n"," |          :math:`k = \\frac{groups}{C_\\text{in} * \\prod_{i=0}^{1}\\text{kernel\\_size}[i]}`\n"," |  \n"," |  Examples:\n"," |  \n"," |      >>> # With square kernels and equal stride\n"," |      >>> m = nn.Conv2d(16, 33, 3, stride=2)\n"," |      >>> # non-square kernels and unequal stride and with padding\n"," |      >>> m = nn.Conv2d(16, 33, (3, 5), stride=(2, 1), padding=(4, 2))\n"," |      >>> # non-square kernels and unequal stride and with padding and dilation\n"," |      >>> m = nn.Conv2d(16, 33, (3, 5), stride=(2, 1), padding=(4, 2), dilation=(3, 1))\n"," |      >>> input = torch.randn(20, 16, 50, 100)\n"," |      >>> output = m(input)\n"," |  \n"," |  .. _cross-correlation:\n"," |      https://en.wikipedia.org/wiki/Cross-correlation\n"," |  \n"," |  .. _link:\n"," |      https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md\n"," |  \n"," |  Method resolution order:\n"," |      Conv2d\n"," |      _ConvNd\n"," |      torch.nn.modules.module.Module\n"," |      builtins.object\n"," |  \n"," |  Methods defined here:\n"," |  \n"," |  __init__(self, in_channels:int, out_channels:int, kernel_size:Union[int, Tuple[int, int]], stride:Union[int, Tuple[int, int]]=1, padding:Union[int, Tuple[int, int]]=0, dilation:Union[int, Tuple[int, int]]=1, groups:int=1, bias:bool=True, padding_mode:str='zeros')\n"," |      Initializes internal Module state, shared by both nn.Module and ScriptModule.\n"," |  \n"," |  forward(self, input:torch.Tensor) -> torch.Tensor\n"," |  \n"," |  ----------------------------------------------------------------------\n"," |  Methods inherited from _ConvNd:\n"," |  \n"," |  __setstate__(self, state)\n"," |  \n"," |  extra_repr(self)\n"," |      Set the extra representation of the module\n"," |      \n"," |      To print customized extra information, you should reimplement\n"," |      this method in your own modules. Both single-line and multi-line\n"," |      strings are acceptable.\n"," |  \n"," |  reset_parameters(self) -> None\n"," |  \n"," |  ----------------------------------------------------------------------\n"," |  Data and other attributes inherited from _ConvNd:\n"," |  \n"," |  __annotations__ = {'_in_channels': <class 'int'>, 'bias': typing.Union...\n"," |  \n"," |  __constants__ = ['stride', 'padding', 'dilation', 'groups', 'padding_m...\n"," |  \n"," |  ----------------------------------------------------------------------\n"," |  Methods inherited from torch.nn.modules.module.Module:\n"," |  \n"," |  __call__ = _call_impl(self, *input, **kwargs)\n"," |  \n"," |  __delattr__(self, name)\n"," |      Implement delattr(self, name).\n"," |  \n"," |  __dir__(self)\n"," |      __dir__() -> list\n"," |      default dir() implementation\n"," |  \n"," |  __getattr__(self, name:str) -> Union[torch.Tensor, _ForwardRef('Module')]\n"," |  \n"," |  __repr__(self)\n"," |      Return repr(self).\n"," |  \n"," |  __setattr__(self, name:str, value:Union[torch.Tensor, _ForwardRef('Module')]) -> None\n"," |      Implement setattr(self, name, value).\n"," |  \n"," |  add_module(self, name:str, module:'Module') -> None\n"," |      Adds a child module to the current module.\n"," |      \n"," |      The module can be accessed as an attribute using the given name.\n"," |      \n"," |      Args:\n"," |          name (string): name of the child module. The child module can be\n"," |              accessed from this module using the given name\n"," |          module (Module): child module to be added to the module.\n"," |  \n"," |  apply(self:~T, fn:Callable[[_ForwardRef('Module')], NoneType]) -> ~T\n"," |      Applies ``fn`` recursively to every submodule (as returned by ``.children()``)\n"," |      as well as self. Typical use includes initializing the parameters of a model\n"," |      (see also :ref:`nn-init-doc`).\n"," |      \n"," |      Args:\n"," |          fn (:class:`Module` -> None): function to be applied to each submodule\n"," |      \n"," |      Returns:\n"," |          Module: self\n"," |      \n"," |      Example::\n"," |      \n"," |          >>> @torch.no_grad()\n"," |          >>> def init_weights(m):\n"," |          >>>     print(m)\n"," |          >>>     if type(m) == nn.Linear:\n"," |          >>>         m.weight.fill_(1.0)\n"," |          >>>         print(m.weight)\n"," |          >>> net = nn.Sequential(nn.Linear(2, 2), nn.Linear(2, 2))\n"," |          >>> net.apply(init_weights)\n"," |          Linear(in_features=2, out_features=2, bias=True)\n"," |          Parameter containing:\n"," |          tensor([[ 1.,  1.],\n"," |                  [ 1.,  1.]])\n"," |          Linear(in_features=2, out_features=2, bias=True)\n"," |          Parameter containing:\n"," |          tensor([[ 1.,  1.],\n"," |                  [ 1.,  1.]])\n"," |          Sequential(\n"," |            (0): Linear(in_features=2, out_features=2, bias=True)\n"," |            (1): Linear(in_features=2, out_features=2, bias=True)\n"," |          )\n"," |          Sequential(\n"," |            (0): Linear(in_features=2, out_features=2, bias=True)\n"," |            (1): Linear(in_features=2, out_features=2, bias=True)\n"," |          )\n"," |  \n"," |  bfloat16(self:~T) -> ~T\n"," |      Casts all floating point parameters and buffers to ``bfloat16`` datatype.\n"," |      \n"," |      Returns:\n"," |          Module: self\n"," |  \n"," |  buffers(self, recurse:bool=True) -> Iterator[torch.Tensor]\n"," |      Returns an iterator over module buffers.\n"," |      \n"," |      Args:\n"," |          recurse (bool): if True, then yields buffers of this module\n"," |              and all submodules. Otherwise, yields only buffers that\n"," |              are direct members of this module.\n"," |      \n"," |      Yields:\n"," |          torch.Tensor: module buffer\n"," |      \n"," |      Example::\n"," |      \n"," |          >>> for buf in model.buffers():\n"," |          >>>     print(type(buf), buf.size())\n"," |          <class 'torch.Tensor'> (20L,)\n"," |          <class 'torch.Tensor'> (20L, 1L, 5L, 5L)\n"," |  \n"," |  children(self) -> Iterator[_ForwardRef('Module')]\n"," |      Returns an iterator over immediate children modules.\n"," |      \n"," |      Yields:\n"," |          Module: a child module\n"," |  \n"," |  cpu(self:~T) -> ~T\n"," |      Moves all model parameters and buffers to the CPU.\n"," |      \n"," |      Returns:\n"," |          Module: self\n"," |  \n"," |  cuda(self:~T, device:Union[int, torch.device, NoneType]=None) -> ~T\n"," |      Moves all model parameters and buffers to the GPU.\n"," |      \n"," |      This also makes associated parameters and buffers different objects. So\n"," |      it should be called before constructing optimizer if the module will\n"," |      live on GPU while being optimized.\n"," |      \n"," |      Arguments:\n"," |          device (int, optional): if specified, all parameters will be\n"," |              copied to that device\n"," |      \n"," |      Returns:\n"," |          Module: self\n"," |  \n"," |  double(self:~T) -> ~T\n"," |      Casts all floating point parameters and buffers to ``double`` datatype.\n"," |      \n"," |      Returns:\n"," |          Module: self\n"," |  \n"," |  eval(self:~T) -> ~T\n"," |      Sets the module in evaluation mode.\n"," |      \n"," |      This has any effect only on certain modules. See documentations of\n"," |      particular modules for details of their behaviors in training/evaluation\n"," |      mode, if they are affected, e.g. :class:`Dropout`, :class:`BatchNorm`,\n"," |      etc.\n"," |      \n"," |      This is equivalent with :meth:`self.train(False) <torch.nn.Module.train>`.\n"," |      \n"," |      Returns:\n"," |          Module: self\n"," |  \n"," |  float(self:~T) -> ~T\n"," |      Casts all floating point parameters and buffers to float datatype.\n"," |      \n"," |      Returns:\n"," |          Module: self\n"," |  \n"," |  half(self:~T) -> ~T\n"," |      Casts all floating point parameters and buffers to ``half`` datatype.\n"," |      \n"," |      Returns:\n"," |          Module: self\n"," |  \n"," |  load_state_dict(self, state_dict:Dict[str, torch.Tensor], strict:bool=True)\n"," |      Copies parameters and buffers from :attr:`state_dict` into\n"," |      this module and its descendants. If :attr:`strict` is ``True``, then\n"," |      the keys of :attr:`state_dict` must exactly match the keys returned\n"," |      by this module's :meth:`~torch.nn.Module.state_dict` function.\n"," |      \n"," |      Arguments:\n"," |          state_dict (dict): a dict containing parameters and\n"," |              persistent buffers.\n"," |          strict (bool, optional): whether to strictly enforce that the keys\n"," |              in :attr:`state_dict` match the keys returned by this module's\n"," |              :meth:`~torch.nn.Module.state_dict` function. Default: ``True``\n"," |      \n"," |      Returns:\n"," |          ``NamedTuple`` with ``missing_keys`` and ``unexpected_keys`` fields:\n"," |              * **missing_keys** is a list of str containing the missing keys\n"," |              * **unexpected_keys** is a list of str containing the unexpected keys\n"," |  \n"," |  modules(self) -> Iterator[_ForwardRef('Module')]\n"," |      Returns an iterator over all modules in the network.\n"," |      \n"," |      Yields:\n"," |          Module: a module in the network\n"," |      \n"," |      Note:\n"," |          Duplicate modules are returned only once. In the following\n"," |          example, ``l`` will be returned only once.\n"," |      \n"," |      Example::\n"," |      \n"," |          >>> l = nn.Linear(2, 2)\n"," |          >>> net = nn.Sequential(l, l)\n"," |          >>> for idx, m in enumerate(net.modules()):\n"," |                  print(idx, '->', m)\n"," |      \n"," |          0 -> Sequential(\n"," |            (0): Linear(in_features=2, out_features=2, bias=True)\n"," |            (1): Linear(in_features=2, out_features=2, bias=True)\n"," |          )\n"," |          1 -> Linear(in_features=2, out_features=2, bias=True)\n"," |  \n"," |  named_buffers(self, prefix:str='', recurse:bool=True) -> Iterator[Tuple[str, torch.Tensor]]\n"," |      Returns an iterator over module buffers, yielding both the\n"," |      name of the buffer as well as the buffer itself.\n"," |      \n"," |      Args:\n"," |          prefix (str): prefix to prepend to all buffer names.\n"," |          recurse (bool): if True, then yields buffers of this module\n"," |              and all submodules. Otherwise, yields only buffers that\n"," |              are direct members of this module.\n"," |      \n"," |      Yields:\n"," |          (string, torch.Tensor): Tuple containing the name and buffer\n"," |      \n"," |      Example::\n"," |      \n"," |          >>> for name, buf in self.named_buffers():\n"," |          >>>    if name in ['running_var']:\n"," |          >>>        print(buf.size())\n"," |  \n"," |  named_children(self) -> Iterator[Tuple[str, _ForwardRef('Module')]]\n"," |      Returns an iterator over immediate children modules, yielding both\n"," |      the name of the module as well as the module itself.\n"," |      \n"," |      Yields:\n"," |          (string, Module): Tuple containing a name and child module\n"," |      \n"," |      Example::\n"," |      \n"," |          >>> for name, module in model.named_children():\n"," |          >>>     if name in ['conv4', 'conv5']:\n"," |          >>>         print(module)\n"," |  \n"," |  named_modules(self, memo:Union[Set[_ForwardRef('Module')], NoneType]=None, prefix:str='')\n"," |      Returns an iterator over all modules in the network, yielding\n"," |      both the name of the module as well as the module itself.\n"," |      \n"," |      Yields:\n"," |          (string, Module): Tuple of name and module\n"," |      \n"," |      Note:\n"," |          Duplicate modules are returned only once. In the following\n"," |          example, ``l`` will be returned only once.\n"," |      \n"," |      Example::\n"," |      \n"," |          >>> l = nn.Linear(2, 2)\n"," |          >>> net = nn.Sequential(l, l)\n"," |          >>> for idx, m in enumerate(net.named_modules()):\n"," |                  print(idx, '->', m)\n"," |      \n"," |          0 -> ('', Sequential(\n"," |            (0): Linear(in_features=2, out_features=2, bias=True)\n"," |            (1): Linear(in_features=2, out_features=2, bias=True)\n"," |          ))\n"," |          1 -> ('0', Linear(in_features=2, out_features=2, bias=True))\n"," |  \n"," |  named_parameters(self, prefix:str='', recurse:bool=True) -> Iterator[Tuple[str, torch.Tensor]]\n"," |      Returns an iterator over module parameters, yielding both the\n"," |      name of the parameter as well as the parameter itself.\n"," |      \n"," |      Args:\n"," |          prefix (str): prefix to prepend to all parameter names.\n"," |          recurse (bool): if True, then yields parameters of this module\n"," |              and all submodules. Otherwise, yields only parameters that\n"," |              are direct members of this module.\n"," |      \n"," |      Yields:\n"," |          (string, Parameter): Tuple containing the name and parameter\n"," |      \n"," |      Example::\n"," |      \n"," |          >>> for name, param in self.named_parameters():\n"," |          >>>    if name in ['bias']:\n"," |          >>>        print(param.size())\n"," |  \n"," |  parameters(self, recurse:bool=True) -> Iterator[torch.nn.parameter.Parameter]\n"," |      Returns an iterator over module parameters.\n"," |      \n"," |      This is typically passed to an optimizer.\n"," |      \n"," |      Args:\n"," |          recurse (bool): if True, then yields parameters of this module\n"," |              and all submodules. Otherwise, yields only parameters that\n"," |              are direct members of this module.\n"," |      \n"," |      Yields:\n"," |          Parameter: module parameter\n"," |      \n"," |      Example::\n"," |      \n"," |          >>> for param in model.parameters():\n"," |          >>>     print(type(param), param.size())\n"," |          <class 'torch.Tensor'> (20L,)\n"," |          <class 'torch.Tensor'> (20L, 1L, 5L, 5L)\n"," |  \n"," |  register_backward_hook(self, hook:Callable[[_ForwardRef('Module'), Union[Tuple[torch.Tensor, ...], torch.Tensor], Union[Tuple[torch.Tensor, ...], torch.Tensor]], Union[NoneType, torch.Tensor]]) -> torch.utils.hooks.RemovableHandle\n"," |      Registers a backward hook on the module.\n"," |      \n"," |      .. warning ::\n"," |      \n"," |          The current implementation will not have the presented behavior\n"," |          for complex :class:`Module` that perform many operations.\n"," |          In some failure cases, :attr:`grad_input` and :attr:`grad_output` will only\n"," |          contain the gradients for a subset of the inputs and outputs.\n"," |          For such :class:`Module`, you should use :func:`torch.Tensor.register_hook`\n"," |          directly on a specific input or output to get the required gradients.\n"," |      \n"," |      The hook will be called every time the gradients with respect to module\n"," |      inputs are computed. The hook should have the following signature::\n"," |      \n"," |          hook(module, grad_input, grad_output) -> Tensor or None\n"," |      \n"," |      The :attr:`grad_input` and :attr:`grad_output` may be tuples if the\n"," |      module has multiple inputs or outputs. The hook should not modify its\n"," |      arguments, but it can optionally return a new gradient with respect to\n"," |      input that will be used in place of :attr:`grad_input` in subsequent\n"," |      computations. :attr:`grad_input` will only correspond to the inputs given\n"," |      as positional arguments.\n"," |      \n"," |      Returns:\n"," |          :class:`torch.utils.hooks.RemovableHandle`:\n"," |              a handle that can be used to remove the added hook by calling\n"," |              ``handle.remove()``\n"," |  \n"," |  register_buffer(self, name:str, tensor:torch.Tensor, persistent:bool=True) -> None\n"," |      Adds a buffer to the module.\n"," |      \n"," |      This is typically used to register a buffer that should not to be\n"," |      considered a model parameter. For example, BatchNorm's ``running_mean``\n"," |      is not a parameter, but is part of the module's state. Buffers, by\n"," |      default, are persistent and will be saved alongside parameters. This\n"," |      behavior can be changed by setting :attr:`persistent` to ``False``. The\n"," |      only difference between a persistent buffer and a non-persistent buffer\n"," |      is that the latter will not be a part of this module's\n"," |      :attr:`state_dict`.\n"," |      \n"," |      Buffers can be accessed as attributes using given names.\n"," |      \n"," |      Args:\n"," |          name (string): name of the buffer. The buffer can be accessed\n"," |              from this module using the given name\n"," |          tensor (Tensor): buffer to be registered.\n"," |          persistent (bool): whether the buffer is part of this module's\n"," |              :attr:`state_dict`.\n"," |      \n"," |      Example::\n"," |      \n"," |          >>> self.register_buffer('running_mean', torch.zeros(num_features))\n"," |  \n"," |  register_forward_hook(self, hook:Callable[..., NoneType]) -> torch.utils.hooks.RemovableHandle\n"," |      Registers a forward hook on the module.\n"," |      \n"," |      The hook will be called every time after :func:`forward` has computed an output.\n"," |      It should have the following signature::\n"," |      \n"," |          hook(module, input, output) -> None or modified output\n"," |      \n"," |      The input contains only the positional arguments given to the module.\n"," |      Keyword arguments won't be passed to the hooks and only to the ``forward``.\n"," |      The hook can modify the output. It can modify the input inplace but\n"," |      it will not have effect on forward since this is called after\n"," |      :func:`forward` is called.\n"," |      \n"," |      Returns:\n"," |          :class:`torch.utils.hooks.RemovableHandle`:\n"," |              a handle that can be used to remove the added hook by calling\n"," |              ``handle.remove()``\n"," |  \n"," |  register_forward_pre_hook(self, hook:Callable[..., NoneType]) -> torch.utils.hooks.RemovableHandle\n"," |      Registers a forward pre-hook on the module.\n"," |      \n"," |      The hook will be called every time before :func:`forward` is invoked.\n"," |      It should have the following signature::\n"," |      \n"," |          hook(module, input) -> None or modified input\n"," |      \n"," |      The input contains only the positional arguments given to the module.\n"," |      Keyword arguments won't be passed to the hooks and only to the ``forward``.\n"," |      The hook can modify the input. User can either return a tuple or a\n"," |      single modified value in the hook. We will wrap the value into a tuple\n"," |      if a single value is returned(unless that value is already a tuple).\n"," |      \n"," |      Returns:\n"," |          :class:`torch.utils.hooks.RemovableHandle`:\n"," |              a handle that can be used to remove the added hook by calling\n"," |              ``handle.remove()``\n"," |  \n"," |  register_parameter(self, name:str, param:torch.nn.parameter.Parameter) -> None\n"," |      Adds a parameter to the module.\n"," |      \n"," |      The parameter can be accessed as an attribute using given name.\n"," |      \n"," |      Args:\n"," |          name (string): name of the parameter. The parameter can be accessed\n"," |              from this module using the given name\n"," |          param (Parameter): parameter to be added to the module.\n"," |  \n"," |  requires_grad_(self:~T, requires_grad:bool=True) -> ~T\n"," |      Change if autograd should record operations on parameters in this\n"," |      module.\n"," |      \n"," |      This method sets the parameters' :attr:`requires_grad` attributes\n"," |      in-place.\n"," |      \n"," |      This method is helpful for freezing part of the module for finetuning\n"," |      or training parts of a model individually (e.g., GAN training).\n"," |      \n"," |      Args:\n"," |          requires_grad (bool): whether autograd should record operations on\n"," |                                parameters in this module. Default: ``True``.\n"," |      \n"," |      Returns:\n"," |          Module: self\n"," |  \n"," |  share_memory(self:~T) -> ~T\n"," |  \n"," |  state_dict(self, destination=None, prefix='', keep_vars=False)\n"," |      Returns a dictionary containing a whole state of the module.\n"," |      \n"," |      Both parameters and persistent buffers (e.g. running averages) are\n"," |      included. Keys are corresponding parameter and buffer names.\n"," |      \n"," |      Returns:\n"," |          dict:\n"," |              a dictionary containing a whole state of the module\n"," |      \n"," |      Example::\n"," |      \n"," |          >>> module.state_dict().keys()\n"," |          ['bias', 'weight']\n"," |  \n"," |  to(self, *args, **kwargs)\n"," |      Moves and/or casts the parameters and buffers.\n"," |      \n"," |      This can be called as\n"," |      \n"," |      .. function:: to(device=None, dtype=None, non_blocking=False)\n"," |      \n"," |      .. function:: to(dtype, non_blocking=False)\n"," |      \n"," |      .. function:: to(tensor, non_blocking=False)\n"," |      \n"," |      .. function:: to(memory_format=torch.channels_last)\n"," |      \n"," |      Its signature is similar to :meth:`torch.Tensor.to`, but only accepts\n"," |      floating point desired :attr:`dtype` s. In addition, this method will\n"," |      only cast the floating point parameters and buffers to :attr:`dtype`\n"," |      (if given). The integral parameters and buffers will be moved\n"," |      :attr:`device`, if that is given, but with dtypes unchanged. When\n"," |      :attr:`non_blocking` is set, it tries to convert/move asynchronously\n"," |      with respect to the host if possible, e.g., moving CPU Tensors with\n"," |      pinned memory to CUDA devices.\n"," |      \n"," |      See below for examples.\n"," |      \n"," |      .. note::\n"," |          This method modifies the module in-place.\n"," |      \n"," |      Args:\n"," |          device (:class:`torch.device`): the desired device of the parameters\n"," |              and buffers in this module\n"," |          dtype (:class:`torch.dtype`): the desired floating point type of\n"," |              the floating point parameters and buffers in this module\n"," |          tensor (torch.Tensor): Tensor whose dtype and device are the desired\n"," |              dtype and device for all parameters and buffers in this module\n"," |          memory_format (:class:`torch.memory_format`): the desired memory\n"," |              format for 4D parameters and buffers in this module (keyword\n"," |              only argument)\n"," |      \n"," |      Returns:\n"," |          Module: self\n"," |      \n"," |      Example::\n"," |      \n"," |          >>> linear = nn.Linear(2, 2)\n"," |          >>> linear.weight\n"," |          Parameter containing:\n"," |          tensor([[ 0.1913, -0.3420],\n"," |                  [-0.5113, -0.2325]])\n"," |          >>> linear.to(torch.double)\n"," |          Linear(in_features=2, out_features=2, bias=True)\n"," |          >>> linear.weight\n"," |          Parameter containing:\n"," |          tensor([[ 0.1913, -0.3420],\n"," |                  [-0.5113, -0.2325]], dtype=torch.float64)\n"," |          >>> gpu1 = torch.device(\"cuda:1\")\n"," |          >>> linear.to(gpu1, dtype=torch.half, non_blocking=True)\n"," |          Linear(in_features=2, out_features=2, bias=True)\n"," |          >>> linear.weight\n"," |          Parameter containing:\n"," |          tensor([[ 0.1914, -0.3420],\n"," |                  [-0.5112, -0.2324]], dtype=torch.float16, device='cuda:1')\n"," |          >>> cpu = torch.device(\"cpu\")\n"," |          >>> linear.to(cpu)\n"," |          Linear(in_features=2, out_features=2, bias=True)\n"," |          >>> linear.weight\n"," |          Parameter containing:\n"," |          tensor([[ 0.1914, -0.3420],\n"," |                  [-0.5112, -0.2324]], dtype=torch.float16)\n"," |  \n"," |  train(self:~T, mode:bool=True) -> ~T\n"," |      Sets the module in training mode.\n"," |      \n"," |      This has any effect only on certain modules. See documentations of\n"," |      particular modules for details of their behaviors in training/evaluation\n"," |      mode, if they are affected, e.g. :class:`Dropout`, :class:`BatchNorm`,\n"," |      etc.\n"," |      \n"," |      Args:\n"," |          mode (bool): whether to set training mode (``True``) or evaluation\n"," |                       mode (``False``). Default: ``True``.\n"," |      \n"," |      Returns:\n"," |          Module: self\n"," |  \n"," |  type(self:~T, dst_type:Union[torch.dtype, str]) -> ~T\n"," |      Casts all parameters and buffers to :attr:`dst_type`.\n"," |      \n"," |      Arguments:\n"," |          dst_type (type or string): the desired type\n"," |      \n"," |      Returns:\n"," |          Module: self\n"," |  \n"," |  zero_grad(self) -> None\n"," |      Sets gradients of all model parameters to zero.\n"," |  \n"," |  ----------------------------------------------------------------------\n"," |  Data descriptors inherited from torch.nn.modules.module.Module:\n"," |  \n"," |  __dict__\n"," |      dictionary for instance variables (if defined)\n"," |  \n"," |  __weakref__\n"," |      list of weak references to the object (if defined)\n"," |  \n"," |  ----------------------------------------------------------------------\n"," |  Data and other attributes inherited from torch.nn.modules.module.Module:\n"," |  \n"," |  T_destination = ~T_destination\n"," |      Type variable.\n"," |      \n"," |      Usage::\n"," |      \n"," |        T = TypeVar('T')  # Can be anything\n"," |        A = TypeVar('A', str, bytes)  # Must be str or bytes\n"," |      \n"," |      Type variables exist primarily for the benefit of static type\n"," |      checkers.  They serve as the parameters for generic types as well\n"," |      as for generic function definitions.  See class Generic for more\n"," |      information on generic types.  Generic functions work as follows:\n"," |      \n"," |        def repeat(x: T, n: int) -> List[T]:\n"," |            '''Return a list containing n references to x.'''\n"," |            return [x]*n\n"," |      \n"," |        def longest(x: A, y: A) -> A:\n"," |            '''Return the longest of two strings.'''\n"," |            return x if len(x) >= len(y) else y\n"," |      \n"," |      The latter example's signature is essentially the overloading\n"," |      of (str, str) -> str and (bytes, bytes) -> bytes.  Also note\n"," |      that if the arguments are instances of some subclass of str,\n"," |      the return type is still plain str.\n"," |      \n"," |      At runtime, isinstance(x, T) and issubclass(C, T) will raise TypeError.\n"," |      \n"," |      Type variables defined with covariant=True or contravariant=True\n"," |      can be used do declare covariant or contravariant generic types.\n"," |      See PEP 484 for more details. By default generic types are invariant\n"," |      in all type variables.\n"," |      \n"," |      Type variables can be introspected. e.g.:\n"," |      \n"," |        T.__name__ == 'T'\n"," |        T.__constraints__ == ()\n"," |        T.__covariant__ == False\n"," |        T.__contravariant__ = False\n"," |        A.__constraints__ == (str, bytes)\n"," |  \n"," |  dump_patches = False\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"TRUhD4gJS517","executionInfo":{"status":"ok","timestamp":1602089804328,"user_tz":-330,"elapsed":4261,"user":{"displayName":"pytorch stuff","photoUrl":"","userId":"00602585404500228461"}}},"source":["#AlexNET\n","class alexnet(nn.Module):\n","    #super().__init__()\n","    def __init__(self):\n","        super(alexnet, self).__init__()\n","        #conv layers\n","        self.conv1= nn.Conv2d(3,96, 11, stride=4, padding=0)\n","        self.conv2= nn.Conv2d(96, 256,  5, stride=1, padding=2)\n","        self.conv3= nn.Conv2d(256, 384,3, stride=1, padding=1)\n","        self.conv4= nn.Conv2d(384, 384,3, stride=1, padding=1 )\n","        self.conv5= nn.Conv2d(384, 256, 3, stride=1, padding=1 )\n","\n","        #maxpool\n","        self.mp1= nn.MaxPool2d(3,stride=2)\n","        self.mp2= nn.MaxPool2d(3,stride=2)\n","        self.mp3= nn.MaxPool2d(3,stride=2)\n","\n","        #relu\n","        self.relu= nn.ReLU()\n","\n","        #fully connected layer\n","        self.fc1= nn.Linear(256*6*6, 4096)\n","        self.fc2= nn.Linear(4096,4096)\n","        self.fc3= nn.Linear(4096,100)\n","\n","    def num_flat_features(self, x):\n","        size = x.size()[1:]  # all dimensions except the batch dimension\n","        num_features = 1\n","        for s in size:\n","            num_features *= s\n","        return num_features\n","\n","    def forward(self,x):\n","        '''\n","        print((self.conv1(x)).size())\n","        print((self.conv2(x)).size())\n","        print((self.conv3(x)).size())\n","        print((self.conv4(x)).size())\n","        '''\n","        #x= F.max_pool2d(F.local_response_norm(self.conv1(x), 3), 3,stride=2)\n","        x= self.conv1(x)\n","        print(x.size())\n","        x= self.relu(x)\n","        x= self.mp1(x)\n","        print(x.size())\n","        x= self.conv2(x)\n","        print(x.size())\n","        x= self.relu(x)\n","        x= self.mp2(x)\n","        print(x.size())\n","        x= self.conv3(x)\n","        print(x.size())\n","        x= self.relu(x)\n","        x= self.conv4(x)\n","        print(x.size())\n","        x= self.relu(x)\n","        x= self.conv5(x)\n","        print(x.size())\n","        x= self.mp3(x)\n","        print(x.size()) \n","        x = x.view(-1, 256*6*6)\n","        print(x.size())\n","        x= self.fc1(x)\n","        print(x.size()) \n","        x= self.fc2(x)\n","        print(x.size()) \n","        x= self.fc3(x)\n","        print(x.size())       \n","\n","       "],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"id":"6I9V1uvLmu55","executionInfo":{"status":"ok","timestamp":1602089804332,"user_tz":-330,"elapsed":4247,"user":{"displayName":"pytorch stuff","photoUrl":"","userId":"00602585404500228461"}}},"source":["img= torch.randn(1, 3, 227,227)"],"execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"id":"-5tb9Urqn_Oz","executionInfo":{"status":"ok","timestamp":1602089804340,"user_tz":-330,"elapsed":4207,"user":{"displayName":"pytorch stuff","photoUrl":"","userId":"00602585404500228461"}},"outputId":"1c474176-30b9-4294-9ea0-83015fa25782","colab":{"base_uri":"https://localhost:8080/"}},"source":["net = alexnet()\n","print(net)"],"execution_count":31,"outputs":[{"output_type":"stream","text":["alexnet(\n","  (conv1): Conv2d(3, 96, kernel_size=(11, 11), stride=(4, 4))\n","  (conv2): Conv2d(96, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","  (conv3): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (conv4): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (conv5): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (mp1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (mp2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (mp3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (relu): ReLU()\n","  (fc1): Linear(in_features=9216, out_features=4096, bias=True)\n","  (fc2): Linear(in_features=4096, out_features=4096, bias=True)\n","  (fc3): Linear(in_features=4096, out_features=100, bias=True)\n",")\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"JMinaswrm6r8","executionInfo":{"status":"ok","timestamp":1602089515602,"user_tz":-330,"elapsed":1378,"user":{"displayName":"pytorch stuff","photoUrl":"","userId":"00602585404500228461"}},"outputId":"4d7603bd-2a18-43b6-fb85-a4f0984a37c1","colab":{"base_uri":"https://localhost:8080/"}},"source":["\"\"\"\n","out = net(input)\n","print(out)\n","\"\"\"\n","out= net(img)\n","print(out)"],"execution_count":26,"outputs":[{"output_type":"stream","text":["torch.Size([1, 96, 55, 55])\n","torch.Size([1, 96, 27, 27])\n","torch.Size([1, 256, 27, 27])\n","torch.Size([1, 256, 13, 13])\n","torch.Size([1, 384, 13, 13])\n","torch.Size([1, 384, 13, 13])\n","torch.Size([1, 256, 13, 13])\n","torch.Size([1, 256, 6, 6])\n","torch.Size([1, 9216])\n","torch.Size([1, 4096])\n","torch.Size([1, 4096])\n","torch.Size([1, 100])\n","None\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4nyWOgk7nHyW","executionInfo":{"status":"ok","timestamp":1602085049735,"user_tz":-330,"elapsed":1394,"user":{"displayName":"pytorch stuff","photoUrl":"","userId":"00602585404500228461"}},"outputId":"13cdd460-88ef-4654-a04a-b21258ea08b9","colab":{"base_uri":"https://localhost:8080/"}},"source":["nn.LocalResponseNorm(2)"],"execution_count":46,"outputs":[{"output_type":"execute_result","data":{"text/plain":["LocalResponseNorm(2, alpha=0.0001, beta=0.75, k=1.0)"]},"metadata":{"tags":[]},"execution_count":46}]},{"cell_type":"code","metadata":{"id":"foTH66jvrRYH","executionInfo":{"status":"ok","timestamp":1602067843376,"user_tz":-330,"elapsed":1467,"user":{"displayName":"pytorch stuff","photoUrl":"","userId":"00602585404500228461"}},"outputId":"1da27c57-f109-4e84-d7d2-1c15b22ef4d2","colab":{"base_uri":"https://localhost:8080/"}},"source":["help(F.local_response_norm)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Help on function local_response_norm in module torch.nn.functional:\n","\n","local_response_norm(input, size, alpha=0.0001, beta=0.75, k=1.0)\n","    Applies local response normalization over an input signal composed of\n","    several input planes, where channels occupy the second dimension.\n","    Applies normalization across channels.\n","    \n","    See :class:`~torch.nn.LocalResponseNorm` for details.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"EVa0T6hjrbv6","executionInfo":{"status":"ok","timestamp":1602086103382,"user_tz":-330,"elapsed":1461,"user":{"displayName":"pytorch stuff","photoUrl":"","userId":"00602585404500228461"}}},"source":["k=nn.MaxPool2d(3,2)"],"execution_count":63,"outputs":[]},{"cell_type":"code","metadata":{"id":"o6Nk-kyexdAU","executionInfo":{"status":"error","timestamp":1602086110055,"user_tz":-330,"elapsed":1546,"user":{"displayName":"pytorch stuff","photoUrl":"","userId":"00602585404500228461"}},"outputId":"08481ea4-f16e-4d65-f9c3-723cbe94dbb3","colab":{"base_uri":"https://localhost:8080/","height":167}},"source":["k(x)"],"execution_count":64,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-64-fb03fd82eeeb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'x' is not defined"]}]},{"cell_type":"code","metadata":{"id":"WmBfiIloxfdt","executionInfo":{"status":"ok","timestamp":1602090724917,"user_tz":-330,"elapsed":1304,"user":{"displayName":"pytorch stuff","photoUrl":"","userId":"00602585404500228461"}}},"source":["class AlexNet(nn.Module):\n","\n","    def __init__(self, num_classes=1000):\n","        super(AlexNet, self).__init__()\n","        self.features = nn.Sequential(\n","            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=3, stride=2),\n","            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=3, stride=2),\n","            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=3, stride=2),\n","        )\n","        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n","        self.classifier = nn.Sequential(\n","            nn.Dropout(),\n","            nn.Linear(256 * 6 * 6, 4096),\n","            nn.ReLU(inplace=True),\n","            nn.Dropout(),\n","            nn.Linear(4096, 4096),\n","            nn.ReLU(inplace=True),\n","            nn.Linear(4096, num_classes),\n","        )\n","\n","    def forward(self, x):\n","        x = self.features(x)\n","        x = self.avgpool(x)\n","        x = torch.flatten(x, 1)\n","        x = self.classifier(x)\n","        return x"],"execution_count":33,"outputs":[]},{"cell_type":"code","metadata":{"id":"fVzx6IZ6DEtF","executionInfo":{"status":"ok","timestamp":1602090743094,"user_tz":-330,"elapsed":1225,"user":{"displayName":"pytorch stuff","photoUrl":"","userId":"00602585404500228461"}},"outputId":"92cf9264-070d-4b00-f8db-fcb047b16f3f","colab":{"base_uri":"https://localhost:8080/"}},"source":["ne= AlexNet()\n","ne"],"execution_count":34,"outputs":[{"output_type":"execute_result","data":{"text/plain":["AlexNet(\n","  (features): Sequential(\n","    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n","    (1): ReLU(inplace=True)\n","    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","    (4): ReLU(inplace=True)\n","    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (7): ReLU(inplace=True)\n","    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (9): ReLU(inplace=True)\n","    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (11): ReLU(inplace=True)\n","    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n","  (classifier): Sequential(\n","    (0): Dropout(p=0.5, inplace=False)\n","    (1): Linear(in_features=9216, out_features=4096, bias=True)\n","    (2): ReLU(inplace=True)\n","    (3): Dropout(p=0.5, inplace=False)\n","    (4): Linear(in_features=4096, out_features=4096, bias=True)\n","    (5): ReLU(inplace=True)\n","    (6): Linear(in_features=4096, out_features=1000, bias=True)\n","  )\n",")"]},"metadata":{"tags":[]},"execution_count":34}]},{"cell_type":"code","metadata":{"id":"HgexJJfjDK9m","executionInfo":{"status":"ok","timestamp":1602090853098,"user_tz":-330,"elapsed":963,"user":{"displayName":"pytorch stuff","photoUrl":"","userId":"00602585404500228461"}},"outputId":"27aab3c7-9daf-46c5-e330-3945e4389f44","colab":{"base_uri":"https://localhost:8080/"}},"source":["net"],"execution_count":35,"outputs":[{"output_type":"execute_result","data":{"text/plain":["alexnet(\n","  (conv1): Conv2d(3, 96, kernel_size=(11, 11), stride=(4, 4))\n","  (conv2): Conv2d(96, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","  (conv3): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (conv4): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (conv5): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (mp1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (mp2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (mp3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (relu): ReLU()\n","  (fc1): Linear(in_features=9216, out_features=4096, bias=True)\n","  (fc2): Linear(in_features=4096, out_features=4096, bias=True)\n","  (fc3): Linear(in_features=4096, out_features=100, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":35}]},{"cell_type":"code","metadata":{"id":"gQYI_UQqDll8"},"source":[""],"execution_count":null,"outputs":[]}]}